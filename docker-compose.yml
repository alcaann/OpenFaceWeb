services:
  openface-api:
    build:
      context: .                    # Keep root as context for shared files
      dockerfile: openface-api/Dockerfile  # Dockerfile location in service folder
    ports:
      - "5000:5000"
    environment:
      - FLASK_ENV=production
      - NVIDIA_VISIBLE_DEVICES=all
      - NVIDIA_DRIVER_CAPABILITIES=compute,utility
    #restart: unless-stopped
    # Enable GPU access
    runtime: nvidia
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
        reservations:
          memory: 2G
          cpus: '1.0'
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      # Mount logs directory to host for persistent logging
      - ./openface-api/logs:/app/openface-api/logs
    # Add shared memory for PyTorch
    shm_size: 1g
